# GitHub Trending ETL Pipeline

## Project Status: COMPLETE âœ…

### Fully Deployed
- âœ… Project structure created
- âœ… GitHub API extractor implemented and tested
- âœ… Extracting both productivity AND development categories
- âœ… 200 repositories extracted (100 per category)
- âœ… S3 bucket created: `github-trending-etl-bucket`
- âœ… Data uploaded to S3 successfully
- âœ… Transform layer: metrics calculation + ranking
- âœ… RDS PostgreSQL instance created and configured
- âœ… 199 repositories loaded to database
- âœ… Step Functions orchestration deployed
- âœ… EventBridge weekly trigger configured
- âœ… Lambda functions deployed (all 3 working)
- âœ… Glue job deployed and tested
- âœ… VPC configuration completed
- âœ… End-to-end pipeline tested successfully
- âœ… Looker Studio dashboard created

### ðŸ“Š Live Dashboard
**View Dashboard**: https://lookerstudio.google.com/reporting/5e400605-ad2f-4f6f-a1b0-af26093cb85e

### Current Data
- **Productivity**: 100 repos (e.g., PowerToys - 129K stars)
- **Development**: 100 repos (e.g., free-for-dev - 117K stars)
- **S3 Location**: `s3://github-trending-etl-bucket/raw/2026-02-05/`

## Next Steps

### 1. ~~Enhance Extractor~~ âœ…
- âœ… Extract both productivity AND development categories
- âœ… Successfully extracting 100 repos per category
- [ ] Add rate limiting handling
- [ ] Add pagination for >100 results

### 2. ~~Create S3 Bucket~~ âœ…
- âœ… Create S3 bucket: `github-trending-etl-bucket`
- âœ… Set up folder structure (raw/, processed/, exports/)
- âœ… Test upload - working!

### 3. Transform Layer (Glue Job)
- âœ… Create data cleaning script
- âœ… Calculate metrics (star velocity, growth rate)
- âœ… Implement trend analysis

### 4. Load Layer (RDS + Lambda)
- âœ… Set up RDS PostgreSQL instance
- âœ… Create database schema
- âœ… Implement data loader Lambda

### 5. Orchestration (Step Functions)
- âœ… Design state machine
- âœ… Set up EventBridge trigger
- [ ] Test end-to-end pipeline

## Quick Start

```bash
# Activate environment
source .venv/bin/activate

# Run extractor locally
python src/extract/github_extractor.py

# Check output
cat data/raw/productivity_2026-02-05.json
```

## AWS Resources Needed
- S3 bucket
- RDS PostgreSQL (db.t3.micro)
- Lambda functions (2)
- Glue Python Shell job
- Step Functions state machine
- EventBridge rule
